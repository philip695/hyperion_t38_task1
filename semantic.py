import spacy

# Here we run the sample code from the T38 document, as per the instructions.

# First we do the simple comparison of 'cat', 'monkey' and 'banana'
nlp = spacy.load('en_core_web_md')
word1 = nlp("cat")
word2 = nlp("monkey")
word3 = nlp("banana")
print(word1.similarity(word2))
print(word3.similarity(word2))
print(word3.similarity(word1))

# Print a separator line.
print("-------------------------")

# Now we use for loops to compare a very slightly longer list of words.
tokens = nlp('cat apple monkey banana ')
for token1 in tokens:
    for token2 in tokens:
        print(token1.text, token2.text, token1.similarity(token2))

# Print a separator line.
print("-------------------------")

# And now we attempt comparison of whole sentences.
sentence_to_compare = "Why is my cat on the car"
sentences = ["where did my dog go",
             "Hello, there is my car",
             "I\'ve lost my car in my car",
             "I\'d like my boat back",
             "I will name my dog Diana"]
model_sentence = nlp(sentence_to_compare)
for sentence in sentences:
    similarity = nlp(sentence).similarity(model_sentence)
    print(sentence + " - ", similarity)

# The similarity scores generated by these sentences seem to align
# essentially with the co-occurrence of lexical items in them and
# with some simple associations between words with similar meanings.
# For example, the highest similarity occurs for 'Hello, there is my
# car' in which three words (my, is, car) are shared with the comparator.
# The similarities in the range > 0.6 < 0.7 are generated by two
# shared words (my, car) and by a shared word (my) and a closely
# associated word (dog - closely associated with cat). The lowest
# ranked similarity occurs with the sentence to do with a boat. This
# still achieves > 0.5 similarity, which is presumably largely to do
# with the one shared word 'my'.


# ---------------------------------------------------------------------
# Write a note about what you found interesting about the similarities
# between cat, monkey and banana and think of an example of your own.

# I found it interesting that the similarities recognise that there is
# some sort of relationship between monkeys and bananas. Obviously this
# does not reflect any conscious understanding of that relationship,
# but rather the model has been informed by factors such as the
# frequency of collocation of the words 'monkey' and 'banana' in text
# corpora. It would be interesting to test this against foodstuffs
# commonly associated with cats, such as fish and cream (see below).

# Print a separator line.
print("-------------------------")

word4 = nlp("fish")
word5 = nlp("cream")
print("cat", "fish", word1.similarity(word4))
print("monkey", "fish", word2.similarity(word4))
print("banana", "fish", word3.similarity(word4))
print("cat", "cream", word1.similarity(word5))
print("monkey", "cream", word2.similarity(word5))
print("banana", "cream", word3.similarity(word5))
print("fish", "cream", word4.similarity(word5))

# The results of these comparisons do not align straightforwardly
# with those encountered with 'cat', 'monkey' and 'banana'. In
# this case, 'fish' shows some increased similarity to 'banana',
# reflecting the fact that both can be foodstuffs, but this is a
# good deal lower than the similarity to 'apple'. This may reflect
# both the fact that 'fish' is not a fruit (OK, I know bananas
# are not technically fruits either, but they are according to
# prevailing folk taxonomies) and the fact that 'fish' can refer
# both to the animal and the foodstuffs derived from it.

# Another interesting area for semantic similarity is in terms
# relating to human relationships. I therefore analysed a number
# of words in this area using the code below.

# Print a separator line.
print("-------------------------")

friends_and_relations = [
    "mum",
    "mother",
    "dad",
    "father",
    "aunt",
    "uncle",
    "cousin",
    "brother",
    "sister",
    "mate",
    "friend",
    "partner"
]

for term1 in friends_and_relations:
    term1_model = nlp(term1)
    for term2 in friends_and_relations:
        print(term1, term2, term1_model.similarity(nlp(term2)))

# The results of these comparisons are interesting and one could
# comment extensively on them. For the sake of brevity, I note three
# especially interesting points:
#
# 1. The formal 'mother' and 'father' and informal 'mum' and 'dad'
#    show high similarity between the two formal forms and high
#    similarity between the two informal forms. These similarity
#    scores are much higher than between the semantically equivalent
#    pairs 'mum/mother' and 'dad/father'. This suggests that the
#    similarity of form of the forms may be more important in
#    gauging their similarity than their actual meaning. This
#    hypothesis is supported by the high similarity scores for
#    'mother/brother' and 'father/brother'.
# 2. There appear to be some signs that gender is indirectly
#    reflected in the similarity scores. For example, 'mum'
#    shows higher similarities to some other terms for female
#    relatives ('aunt', 'sister'). At the same time, there are
#    still some relatively high cross gender similarities (e.g.
#    'mum/uncle'). This may partly be a question of how
#    commonly these terms collocate with one another in training
#    data (and this may be another factor relevant to point 1).
# 3. The similarities between 'friend', 'mate' and 'partner' do
#    not straightforwardly reflect any intuitions about these
#    terms. The term 'partner' is complicated by its use in very
#    different ways in, for instance, business contexts and
#    personal relationships. It is surprising in some ways that
#    'mate' and 'friend' do not have an especially high
#    similarity if we consider their broadly equivalent semantic
#    force. On the other hand, we should also allow for the fact
#    that 'mate' could represent the verb and can also be used
#    to refer to the sexual partner of a non-human animal.


# ---------------------------------------------------------------------
# Run the example file with the simpler language model ‘en_core_web_sm’
# and write a note on what you notice is different from the model
# 'en_core_web_md'.

# Doing this produces warnings that the model has no word vectors loaded
# and that it may therefore 'not give useful similarity judgements'.
# The similarity judgements are mostly lowered across the board with this
# model, although there are some surprising high scores when comparing
# complaints and recipes (as well as some very low scores). Interestingly,
# complaints are rated less similar to other complaints using this model,
# whereas recipes generally still have relatively high scores of similarity
# to one another. This may reflect the somewhat more formulaic quality of
# recipes, which tend to contain similar kinds of syntactic structure in a
# way that is less likely to be true of complaints.
